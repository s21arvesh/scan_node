
name: Dynamic JavaScript Code Scan

on:
  workflow_dispatch:
    inputs:
      scan_tools:
        description: 'Comma-separated list of tools to run'
        required: false
        default: 'eslint,plato'
      project_name:
        description: 'Project name for reporting'
        required: false
        default: 'javascript-project'

env:
  REPORT_DIR: scan-reports

jobs:
  javascript-scan:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        
    - name: Install dependencies
      run: |
        npm install -g eslint npm retire plato jsdoc jscpd
        pip install osv-scanner || true
        curl -sSfL https://raw.githubusercontent.com/anchore/syft/main/install.sh | sudo sh -s -- -b /usr/local/bin
        curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sudo sh -s -- -b /usr/local/bin
        curl -sSfL https://raw.githubusercontent.com/anchore/grype/main/install.sh | sudo sh -s -- -b /usr/local/bin
        pip install scancode-toolkit
        pip install trufflehog3
        curl -sL https://github.com/gitleaks/gitleaks/releases/latest/download/gitleaks_8.18.2_linux_x64.tar.gz -o gitleaks.tar.gz && tar -xzf gitleaks.tar.gz gitleaks && sudo mv gitleaks /usr/local/bin/gitleaks && chmod +x /usr/local/bin/gitleaks
        echo "Verifying installations:"
        which eslint || echo "eslint not found in PATH"
        which plato || echo "plato not found in PATH"
        which retire || echo "retire not found in PATH"
        which jscpd || echo "jscpd not found in PATH"
        which jsdoc || echo "jsdoc not found in PATH"
        which osv-scanner || echo "osv-scanner not found in PATH"
        which syft || echo "syft not found in PATH"
        which grype || echo "grype not found in PATH"
        which trivy || echo "trivy not found in PATH"
        which scancode || echo "scancode not found in PATH"
        which trufflehog || echo "trufflehog not found in PATH"
        which gitleaks || echo "gitleaks not found in PATH"
        echo ""
        echo "Version checks:"
        eslint --version || echo "eslint version failed"
        plato --version || echo "plato version failed"
        retire --version || echo "retire version failed"
        jscpd --version || echo "jscpd version failed"
        jsdoc --version || echo "jsdoc version failed"
        osv-scanner --version || echo "OSV Scanner version failed"
        syft --version || echo "Syft version failed"
        grype --version || echo "Grype version failed"
        trivy --version || echo "Trivy version failed"
        scancode --version || echo "ScanCode version failed"
        trufflehog --version || echo "TruffleHog version failed"
        gitleaks --version || echo "Gitleaks version failed"
        
    - name: Create report directory
      run: mkdir -p $REPORT_DIR

    - name: Create ESLint config
      run: |
        printf '{"env":{"browser":true,"es2021":true,"node":true,"commonjs":true},"extends":["eslint:recommended"],"parserOptions":{"ecmaVersion":12,"sourceType":"commonjs"},"rules":{"no-var":"error","semi":"error","no-unused-vars":"error","no-alert":"error","quotes":["error","double"],"no-undef":"error"}}' > .eslintrc.json
        cat .eslintrc.json

    - name: Run JavaScript code scans
      run: |
        echo "Starting JavaScript code scans..."
        echo "Current directory: $(pwd)"
        echo "Report directory: $REPORT_DIR"
        echo "JavaScript files found:"
        find . -name "*.js" -type f | head -10 || echo "No JavaScript files found"
        test "$(find . -name '*.js' | wc -l)" -gt 0 || echo "❌ No JS files for Plato"
        echo "Package.json exists:"
        test -f package.json && echo "✅ package.json found" || echo "❌ package.json not found"
        echo "Node modules exists:"
        test -d node_modules && echo "✅ node_modules found" || echo "❌ node_modules not found"
        echo "=== Running Scan Commands ==="
                # ESLint
        eslint . -f json -o $REPORT_DIR/eslint.json || true

        # NPM Audit
        npm install --package-lock-only || true
        npm audit --json > $REPORT_DIR/npm_audit.json || true

        # Retire.js
        retire --js --nodepath node_modules --outputformat json --outputpath $REPORT_DIR/retire.json . || true

        # Plato
        plato -r -x 'node_modules' -d $REPORT_DIR/plato-report . || true

        # JSDoc
        find . -maxdepth 2 -name '*.js' -not -path './node_modules/*' | head -50 | xargs jsdoc -X > $REPORT_DIR/jsdoc.json 2>/dev/null || true

        # JSCPD
        jscpd . --reporters json --output $REPORT_DIR --min-lines 3 --min-tokens 25 --ignore "node_modules" || true
        test -f $REPORT_DIR/jscpd-report.json || echo '{"duplicates":[],"statistics":{"total":{"percentage":0}}}' > $REPORT_DIR/jscpd-report.json

        # OSV Scanner
        osv-scanner scan . --format json --output $REPORT_DIR/osv_scanner.json 2>/dev/null || echo '{"results": []}' > $REPORT_DIR/osv_scanner.json

        # Syft SBOM
        syft . -o json=$REPORT_DIR/syft.json 2>/dev/null || echo '{"artifacts": []}' > $REPORT_DIR/syft.json

        # Trivy
        trivy fs --format json --output $REPORT_DIR/trivy.json . 2>/dev/null || echo '{"Results": []}' > $REPORT_DIR/trivy.json

        # Grype
        grype dir:. -o json > $REPORT_DIR/grype.json 2>/dev/null || echo '{"matches": []}' > $REPORT_DIR/grype.json

        # ScanCode
        scancode . --json $REPORT_DIR/scancode.json --copyright --license --package --info 2>/dev/null || echo '{"files": []}' > $REPORT_DIR/scancode.json

        # TruffleHog
        echo "Running TruffleHog..."
        echo "Scanning filesystem..."
        trufflehog filesystem --directory . --json --output $REPORT_DIR/trufflehog.json || echo '{"FoundIssues": []}' > $REPORT_DIR/trufflehog.json
        echo "Scanning git history..."
        trufflehog git . --json --output $REPORT_DIR/trufflehog_git.json || echo '{"FoundIssues": []}' > $REPORT_DIR/trufflehog_git.json
        echo "TruffleHog completed. File sizes: filesystem $(wc -c < $REPORT_DIR/trufflehog.json) bytes, git $(wc -c < $REPORT_DIR/trufflehog_git.json) bytes"

        # Gitleaks
        gitleaks detect --source . --report-format json --report-path $REPORT_DIR/gitleaks.json --no-git 2>/dev/null || echo '[]' > $REPORT_DIR/gitleaks.json
        echo "=== Scan Commands Completed ==="
        echo "Report directory contents after scans:"
        ls -la $REPORT_DIR/ || echo "Report directory not accessible"
        
    - name: Generate severity summary
      run: |
        python3 << 'PYEOF'
        import json
        import os
        from pathlib import Path
        
        report_dir = Path(os.environ.get('REPORT_DIR', 'scan-reports'))
        
        severity_summary = dict()
        severity_summary['critical'] = []
        severity_summary['high'] = []
        severity_summary['medium'] = []
        severity_summary['low'] = []
        severity_summary['info'] = []

        # Process ESLint results
        eslint_file = report_dir / 'eslint.json'
        if eslint_file.exists() and eslint_file.stat().st_size > 0:
            try:
                with open(eslint_file) as f:
                    eslint_data = json.load(f)
                    for result in eslint_data:
                        if result.get('errorCount', 0) > 0 or result.get('warningCount', 0) > 0:
                            for message in result.get('messages', []):
                                severity = 'high' if message.get('severity') == 2 else 'medium'
                                severity_summary[severity].append(dict(
                                    tool='eslint',
                                    file='./' + result.get('filePath', '').lstrip('./'),
                                    line=message.get('line'),
                                    column=message.get('column'),
                                    issue=message.get('ruleId'),
                                    message=message.get('message')
                                ))
            except Exception as e:
                print('Error processing eslint.json: ' + str(e))

        # Process NPM Audit results
        npm_audit_file = report_dir / 'npm_audit.json'
        if npm_audit_file.exists() and npm_audit_file.stat().st_size > 0:
            try:
                with open(npm_audit_file) as f:
                    npm_audit_data = json.load(f)
                    vuln_count = 0
                    vulns = npm_audit_data.get('vulnerabilities', {})
                    for pkg, vuln in vulns.items():
                        vuln_count += 1
                        audit_severity = vuln.get('severity', 'unknown').lower()
                        if audit_severity in ['critical', 'high']:
                            severity = 'critical'
                        elif audit_severity in ['medium', 'moderate']:
                            severity = 'high'
                        elif audit_severity in ['low']:
                            severity = 'medium'
                        else:
                            severity = 'low'

                        if severity in severity_summary:
                            severity_summary[severity].append(dict(
                                tool='npm_audit',
                                file='./package.json',
                                line=1,
                                issue=vuln.get('name', pkg),
                                message=vuln.get('title', 'Security vulnerability'),
                                severity=vuln.get('severity', 'unknown'),
                                url=vuln.get('url', 'No URL')
                            ))
            except Exception as e:
                print('Error processing npm_audit.json: ' + str(e))

        # Process Retire.js results
        retire_file = report_dir / 'retire.json'
        if retire_file.exists() and retire_file.stat().st_size > 0:
            try:
                with open(retire_file) as f:
                    retire_data = json.load(f)
                    vuln_count = 0
                    # FIX 1 & 2: Handle correct Retire.js JSON structure
                    for file_entry in retire_data.get('data', []):
                        for component in file_entry.get('results', []):
                            if 'vulnerabilities' in component and component['vulnerabilities']:
                                for vuln in component['vulnerabilities']:
                                    vuln_count += 1
                                    # FIX 3: Add fallback severity
                                    retire_severity = vuln.get('severity', 'medium').lower()
                                    if retire_severity in ['critical', 'high']:
                                        severity = 'critical'
                                    elif retire_severity in ['medium', 'moderate']:
                                        severity = 'high'
                                    elif retire_severity in ['low']:
                                        severity = 'medium'
                                    else:
                                        severity = 'low'

                                    if severity in severity_summary:
                                        severity_summary[severity].append(dict(
                                            tool='retire',
                                            # FIX 2: Use correct file path from file_entry
                                            file='./' + file_entry.get('file', 'unknown').lstrip('./'),
                                            line=1,
                                            issue=component.get('component', 'unknown-component'),
                                            message=vuln.get('identifiers', {}).get('summary', 'Security vulnerability'),
                                            severity=vuln.get('severity', 'medium'),
                                            info=vuln.get('info', 'No additional info')
                                        ))
            except Exception as e:
                print('Error processing retire.json: ' + str(e))

        # Process Plato complexity results
        plato_report_file = report_dir / 'plato-report' / 'report.json'
        if plato_report_file.exists() and plato_report_file.stat().st_size > 0:
            try:
                with open(plato_report_file) as f:
                    plato_data = json.load(f)
                    # FIX 1-4: Handle correct Plato JSON structure
                    reports = plato_data.get('reports', {})
                    for file_path, report_item in reports.items():
                        if isinstance(report_item, dict):
                            # FIX 2: Use correct file path from iteration key
                            file_path = './' + file_path.lstrip('./')
                            # FIX 3: Use report_item for maintainability
                            maintainability = report_item.get('maintainability', 0)
                            # FIX 4: Use correct complexity path
                            complexity = report_item.get('complexity', {}).get('aggregate', {}).get('cyclomatic', 0)

                            # Map complexity values to severity
                            if complexity > 15:
                                severity_summary['high'].append(dict(
                                    tool='plato',
                                    file=file_path,
                                    line=1,
                                    issue='high_complexity',
                                    message='Cyclomatic complexity: ' + str(complexity)
                                ))
                            elif complexity > 10:
                                severity_summary['medium'].append(dict(
                                    tool='plato',
                                    file=file_path,
                                    line=1,
                                    issue='medium_complexity',
                                    message='Cyclomatic complexity: ' + str(complexity)
                                ))

                            if maintainability < 60:
                                severity_summary['medium'].append(dict(
                                    tool='plato',
                                    file=file_path,
                                    line=1,
                                    issue='low_maintainability',
                                    message='Maintainability score: ' + str(maintainability)
                                ))
                            elif maintainability < 80:
                                severity_summary['low'].append(dict(
                                    tool='plato',
                                    file=file_path,
                                    line=1,
                                    issue='medium_maintainability',
                                    message='Maintainability score: ' + str(maintainability)
                                ))
            except Exception as e:
                print('Error processing plato report: ' + str(e))

        # Debug: Check file existence
        for f in ['npm_audit.json', 'retire.json', 'jscpd-report.json', 'jsdoc.json', 'osv_scanner.json', 'syft.json', 'trivy.json', 'grype.json', 'scancode.json', 'trufflehog.json', 'gitleaks.json']:
            p = report_dir / f
            print(f, 'exists:', p.exists(), 'size:', p.stat().st_size if p.exists() else 0)

        # Process JSCPD results
        jscpd_file = report_dir / 'jscpd-report.json'
        if jscpd_file.exists() and jscpd_file.stat().st_size > 0:
            try:
                with open(jscpd_file) as f:
                    jscpd_data = json.load(f)

                    total_duplicates = jscpd_data.get('total', {}).get('duplicates', 0)
                    total_lines = jscpd_data.get('total', {}).get('lines', 0)
                    percentage = jscpd_data.get('total', {}).get('percentage', 0)

                    # Use duplication percentage for severity mapping
                    duplication_percentage = jscpd_data.get('statistics', {}).get('duplicationPercentage', percentage)

                    if total_duplicates > 0:
                        severity = 'high' if duplication_percentage > 20 else 'medium' if duplication_percentage >= 10 else 'low'
                        severity_summary[severity].append(dict(
                            tool='jscpd',
                            file='./',
                            line=1,
                            issue='code_duplication',
                            message=f'Found {total_duplicates} duplicates ({duplication_percentage:.1f}% of code)'
                        ))
            except Exception as e:
                print('Error processing jscpd-report.json: ' + str(e))

        # Process JSDoc results
        jsdoc_file = report_dir / 'jsdoc.json'
        if jsdoc_file.exists() and jsdoc_file.stat().st_size > 0:
            try:
                with open(report_dir / 'jsdoc.json') as f:
                    jsdoc_data = json.load(f)

                    # Parse undocumented entries
                    if isinstance(jsdoc_data, dict) and 'docs' in jsdoc_data:
                        for doc_entry in jsdoc_data['docs']:
                            if isinstance(doc_entry, dict) and doc_entry.get('undocumented', False):
                                severity_summary['info'].append(dict(
                                    tool='jsdoc',
                                    file='./' + doc_entry.get('meta', {}).get('filename', 'unknown').lstrip('./'),
                                    name=doc_entry.get('name', 'unknown'),
                                    line=doc_entry.get('meta', {}).get('lineno', 1),
                                    message='Missing JSDoc comment'
                                ))
                    else:
                        # Fallback for different JSDoc output formats
                        severity_summary['info'].append(dict(
                            tool='jsdoc',
                            file='./',
                            line=1,
                            issue='documentation_scan',
                            message=f'JSDoc scanned {len(jsdoc_data) if isinstance(jsdoc_data, (list, dict)) else 0} symbols'
                        ))
            except Exception as e:
                print('Error processing jsdoc.json: ' + str(e))

        # Process OSV Scanner results
        osv_file = report_dir / 'osv_scanner.json'
        if osv_file.exists() and osv_file.stat().st_size > 0:
            try:
                with open(osv_file) as f:
                    osv_data = json.load(f)
                    for result in osv_data.get('results', []):
                        for pkg in result.get('packages', []):
                            for vuln in pkg.get('vulnerabilities', []):
                                sev = vuln.get('database_specific', {}).get('severity', 'MODERATE').upper()
                                mapped = 'critical' if sev == 'CRITICAL' else 'high' if sev == 'HIGH' else 'medium' if sev in ('MODERATE', 'MEDIUM') else 'low'
                                severity_summary[mapped].append(dict(
                                    tool='osv_scanner',
                                    file=pkg.get('package', {}).get('name', 'unknown'),
                                    line=1,
                                    issue=vuln.get('id', 'unknown'),
                                    message=vuln.get('summary', 'Vulnerability detected')
                                ))
            except Exception as e:
                print('Error processing osv_scanner.json: ' + str(e))

        # Process Trivy results
        trivy_file = report_dir / 'trivy.json'
        if trivy_file.exists() and trivy_file.stat().st_size > 0:
            try:
                with open(trivy_file) as f:
                    trivy_data = json.load(f)
                    for result in trivy_data.get('Results', []):
                        for vuln in result.get('Vulnerabilities', []):
                            sev = vuln.get('Severity', 'MEDIUM').upper()
                            mapped = 'critical' if sev == 'CRITICAL' else 'high' if sev == 'HIGH' else 'medium' if sev == 'MEDIUM' else 'low'
                            severity_summary[mapped].append(dict(
                                tool='trivy',
                                file=result.get('Target', 'unknown'),
                                line=1,
                                issue=vuln.get('VulnerabilityID', 'unknown'),
                                message=vuln.get('Title', vuln.get('Description', 'Vulnerability detected'))
                            ))
            except Exception as e:
                print('Error processing trivy.json: ' + str(e))

        # Process Grype results
        grype_file = report_dir / 'grype.json'
        if grype_file.exists() and grype_file.stat().st_size > 0:
            try:
                with open(grype_file) as f:
                    grype_data = json.load(f)
                    for match in grype_data.get('matches', []):
                        vuln = match.get('vulnerability', {})
                        sev = vuln.get('severity', 'Medium').upper()
                        mapped = 'critical' if sev == 'CRITICAL' else 'high' if sev == 'HIGH' else 'medium' if sev == 'MEDIUM' else 'low'
                        artifact = match.get('artifact', {})
                        severity_summary[mapped].append(dict(
                            tool='grype',
                            file=artifact.get('name', 'unknown'),
                            line=1,
                            issue=vuln.get('id', 'unknown'),
                            message=vuln.get('description', 'Vulnerability detected'),
                            version=artifact.get('version', 'unknown')
                        ))
            except Exception as e:
                print('Error processing grype.json: ' + str(e))

        # Process ScanCode results
        scancode_file = report_dir / 'scancode.json'
        if scancode_file.exists() and scancode_file.stat().st_size > 0:
            try:
                with open(scancode_file) as f:
                    scancode_data = json.load(f)
                    for file_entry in scancode_data.get('files', []):
                        for license_det in file_entry.get('license_detections', []):
                            severity_summary['info'].append(dict(
                                tool='scancode',
                                file='./' + file_entry.get('path', 'unknown').lstrip('./'),
                                line=1,
                                issue='license_detection',
                                message='License: ' + license_det.get('license_expression', 'unknown')
                            ))
                        for copyright_det in file_entry.get('copyrights', []):
                            severity_summary['info'].append(dict(
                                tool='scancode',
                                file='./' + file_entry.get('path', 'unknown').lstrip('./'),
                                line=1,
                                issue='copyright_detection',
                                message='Copyright: ' + copyright_det.get('copyright', 'unknown')
                            ))
            except Exception as e:
                print('Error processing scancode.json: ' + str(e))

        # Process TruffleHog results (both filesystem and git scans)
        trufflehog_files = ['trufflehog.json', 'trufflehog_git.json']
        for trufflehog_filename in trufflehog_files:
            trufflehog_file = report_dir / trufflehog_filename
            if trufflehog_file.exists() and trufflehog_file.stat().st_size > 0:
                try:
                    with open(trufflehog_file) as f:
                        trufflehog_data = json.load(f)
                        
                        # Handle TruffleHog v3 format: {"FoundIssues": [...]}
                        if isinstance(trufflehog_data, dict) and 'FoundIssues' in trufflehog_data:
                            for finding in trufflehog_data.get('FoundIssues', []):
                                source_type = 'git' if 'git' in trufflehog_filename else 'filesystem'
                                severity_summary['critical'].append(dict(
                                    tool='trufflehog',
                                    file=finding.get('SourceMetadata', {}).get('Data', {}).get('Filesystem', {}).get('file', 'unknown'),
                                    line=finding.get('SourceMetadata', {}).get('Data', {}).get('Filesystem', {}).get('line', 1),
                                    issue=finding.get('DetectorName', 'secret_detected'),
                                    message=f'Secret detected ({source_type}): ' + finding.get('DetectorName', 'unknown type')
                                ))
                        # Handle array format (fallback)
                        elif isinstance(trufflehog_data, list):
                            source_type = 'git' if 'git' in trufflehog_filename else 'filesystem'
                            for finding in trufflehog_data:
                                severity_summary['critical'].append(dict(
                                    tool='trufflehog',
                                    file=finding.get('SourceMetadata', {}).get('Data', {}).get('Filesystem', {}).get('file', 'unknown'),
                                    line=finding.get('SourceMetadata', {}).get('Data', {}).get('Filesystem', {}).get('line', 1),
                                    issue=finding.get('DetectorName', 'secret_detected'),
                                    message=f'Secret detected ({source_type}): ' + finding.get('DetectorName', 'unknown type')
                                ))
                except Exception as e:
                    print(f'Error processing {trufflehog_filename}: ' + str(e))

        # Process Gitleaks results
        gitleaks_file = report_dir / 'gitleaks.json'
        if gitleaks_file.exists() and gitleaks_file.stat().st_size > 0:
            try:
                with open(gitleaks_file) as f:
                    gitleaks_data = json.load(f)
                    if isinstance(gitleaks_data, list):
                        for finding in gitleaks_data:
                            severity_summary['critical'].append(dict(
                                tool='gitleaks',
                                file='./' + finding.get('File', 'unknown').lstrip('./'),
                                line=finding.get('StartLine', 1),
                                issue=finding.get('RuleID', 'secret_detected'),
                                message='Secret detected: ' + finding.get('Description', 'unknown type')
                            ))
            except Exception as e:
                print('Error processing gitleaks.json: ' + str(e))

        # Process Syft results
        syft_file = report_dir / 'syft.json'
        if syft_file.exists() and syft_file.stat().st_size > 0:
            try:
                with open(syft_file) as f:
                    syft_data = json.load(f)
                    artifacts = syft_data.get('artifacts', [])
                    severity_summary['info'].append(dict(
                        tool='syft',
                        file='./',
                        line=1,
                        issue='sbom_generated',
                        message='SBOM generated with ' + str(len(artifacts)) + ' artifacts/packages detected'
                    ))
            except Exception as e:
                print('Error processing syft.json: ' + str(e))

        # Save severity summary
        output_file = report_dir / 'severity_summary.json'
        with open(output_file, 'w') as f:
            json.dump(severity_summary, f, indent=2)

        print('=== FINAL SEVERITY SUMMARY ===')
        for severity, issues in severity_summary.items():
            print(str(severity) + ': ' + str(len(issues)) + ' issues')
        print('Severity summary saved to: ' + str(output_file))
        PYEOF
        
    - name: Verify scan outputs
      run: |
        ls -R $REPORT_DIR
        test -f $REPORT_DIR/eslint.json || echo "❌ eslint missing"
        test -f $REPORT_DIR/npm_audit.json || echo "❌ npm audit missing"
        test -f $REPORT_DIR/retire.json || echo "❌ retire missing"
        test -f $REPORT_DIR/jscpd-report.json || echo "❌ jscpd missing"
        test -f $REPORT_DIR/jsdoc.json || echo "❌ jsdoc missing"
        test -f $REPORT_DIR/plato-report/report.json || echo "❌ plato missing"
        test -f $REPORT_DIR/osv_scanner.json || echo "❌ osv_scanner missing"
        test -f $REPORT_DIR/syft.json || echo "❌ syft missing"
        test -f $REPORT_DIR/trivy.json || echo "❌ trivy missing"
        test -f $REPORT_DIR/grype.json || echo "❌ grype missing"
        test -f $REPORT_DIR/scancode.json || echo "❌ scancode missing"
        test -f $REPORT_DIR/trufflehog.json || echo "❌ trufflehog filesystem missing"
        test -f $REPORT_DIR/trufflehog_git.json || echo "❌ trufflehog git missing"
        test -f $REPORT_DIR/gitleaks.json || echo "❌ gitleaks missing"

    - name: Upload scan reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: javascript-scan-reports
        path: ${{ env.REPORT_DIR }}/
        retention-days: 30
