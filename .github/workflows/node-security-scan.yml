name: "Node.js Security Scan - Dynamic"

on:
  workflow_dispatch:

env:
  REPORT_DIR: scan-reports

jobs:
  node-scan:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: "18"
        
    - name: Install dependencies
      run: |
        set +e
        if [ -f "package.json" ]; then
          if [ -f "package-lock.json" ]; then
            npm ci --no-audit --no-fund || npm install --no-audit --no-fund || true
          else
            npm install --no-audit --no-fund || true
          fi
        else
          echo '{"name": "test-project", "version": "1.0.0"}' > package.json
        fi
        set -e
        
    - name: Install additional scan tools
      run: |
        echo "Installing Go for dependency scanning tools..."
        if command -v go >/dev/null 2>&1; then
          echo "Go is already installed"
        else
          echo "Installing Go..."
          wget -q https://go.dev/dl/go1.21.0.linux-amd64.tar.gz
          sudo tar -C /usr/local -xzf go1.21.0.linux-amd64.tar.gz
        fi
        export PATH=$PATH:/usr/local/go/bin:$HOME/go/bin
        echo "PATH=$PATH:/usr/local/go/bin:$HOME/go/bin" >> $GITHUB_ENV
        
        echo "Installing dependency scanning tools..."
        # Install OSV Scanner (try pip first, fallback to Go)
        pip install osv-scanner || (go install github.com/google/osv-scanner/cmd/osv-scanner@latest) || echo "OSV Scanner installation failed"
        
        # Install Syft
        curl -sSfL https://raw.githubusercontent.com/anchore/syft/main/install.sh | sh -s -- -b /usr/local/bin || echo "Syft installation failed"
        
        # Install Grype  
        curl -sSfL https://raw.githubusercontent.com/anchore/grype/main/install.sh | sh -s -- -b /usr/local/bin || echo "Grype installation failed"
        
        # Install Trivy
        curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin || echo "Trivy installation failed"
        
        # Install ScanCode Toolkit
        pip install scancode-toolkit || echo "ScanCode installation failed"
        
        # Install TruffleHog
        pip install trufflehog3 || echo "TruffleHog installation failed"
        
        # Install Gitleaks
        GITLEAKS_VERSION=$(curl -s https://api.github.com/repos/gitleaks/gitleaks/releases/latest | grep '"tag_name"' | sed -E 's/.*"v([^"]+)".*/\1/')
        wget -q "https://github.com/gitleaks/gitleaks/releases/download/v${GITLEAKS_VERSION}/gitleaks_${GITLEAKS_VERSION}_linux_x64.tar.gz" -O /tmp/gitleaks.tar.gz && sudo tar -xzf /tmp/gitleaks.tar.gz -C /usr/local/bin gitleaks && sudo chmod +x /usr/local/bin/gitleaks || echo "Gitleaks installation failed"
        
        export PATH=$PATH:/usr/local/bin:/usr/local/go/bin:$HOME/go/bin
        echo "PATH=$PATH:/usr/local/bin:/usr/local/go/bin:$HOME/go/bin" >> $GITHUB_ENV
        
        # Install any additional complex tools dynamically
        npm install -g retire jscpd jsdoc eslint npm plato

    - name: Create report directory
      run: mkdir -p $REPORT_DIR

    - name: Create ESLint config
      run: |
        printf '{"env":{"node":true,"es2021":true,"commonjs":true},"extends":["eslint:recommended"],"parserOptions":{"ecmaVersion":12,"sourceType":"script"},"rules":{"no-eval":"error","no-unused-vars":"error","no-console":"warn","no-undef":"error"}}' > .eslintrc.json
        cat .eslintrc.json

    - name: Run Node.js code scans
      run: |
        echo "Starting Node.js code scans..."
        echo "JavaScript files found:"
        find . -name '*.js' -not -path './node_modules/*' -type f | head -20 || echo "No JS files found"
        echo "=== Running Scan Commands ==="
                # Syft SBOM
        syft . -o json=$REPORT_DIR/syft.json 2>/dev/null || echo '{"artifacts": []}' > $REPORT_DIR/syft.json

        # Retire.js
        retire --js --nodepath node_modules --outputformat json --outputpath $REPORT_DIR/retire.json . || true

        # OSV Scanner
        osv-scanner scan . --format json --output $REPORT_DIR/osv_scanner.json 2>/dev/null || echo '{"results": []}' > $REPORT_DIR/osv_scanner.json

        # JSCPD
        jscpd . --reporters json --output $REPORT_DIR --min-lines 3 --min-tokens 25 --ignore "node_modules" || true

        # JSDoc
        find . -maxdepth 2 -name '*.js' -not -path './node_modules/*' | head -50 | xargs jsdoc -X > $REPORT_DIR/jsdoc.json 2>/dev/null || true

        # ESLint
        eslint . --no-eslintrc -c .eslintrc.json -f json -o $REPORT_DIR/eslint.json --ignore-pattern node_modules/ || true

        # NPM Audit
        npm install --package-lock-only || true
        npm audit --json > $REPORT_DIR/npm_audit.json || true

        # Trivy
        trivy fs --format json --output $REPORT_DIR/trivy.json . 2>/dev/null || echo '{"Results": []}' > $REPORT_DIR/trivy.json

        # Grype
        grype dir:. -o json > $REPORT_DIR/grype.json 2>/dev/null || echo '{"matches": []}' > $REPORT_DIR/grype.json

        # Plato
        plato -r -x 'node_modules' -d $REPORT_DIR/plato-report . || true
        echo "=== Scan Commands Completed ==="
        echo "Report directory contents:"
        ls -la $REPORT_DIR/ || echo "Report directory not accessible"

    - name: Generate severity summary
      run: |
        python3 << 'PYEOF'
        import json, os
        from pathlib import Path
        
        report_dir = Path(os.environ.get('REPORT_DIR', 'scan-reports'))
        
        severity_summary = {'critical': [], 'high': [], 'medium': [], 'low': [], 'info': []}

        # Process ESLint results
        eslint_file = report_dir / 'eslint.json'
        if eslint_file.exists() and eslint_file.stat().st_size > 0:
            try:
                with open(eslint_file) as f:
                    for result in json.load(f):
                        for msg in result.get('messages', []):
                            sev = 'high' if msg.get('severity') == 2 else 'medium'
                            severity_summary[sev].append(dict(
                                tool='eslint',
                                file=result.get('filePath', 'unknown'),
                                line=msg.get('line'), column=msg.get('column'),
                                issue=msg.get('ruleId'), message=msg.get('message')))
            except Exception as e:
                print('Error processing eslint.json: ' + str(e))

        # Process NPM Audit results
        npm_file = report_dir / 'npm_audit.json'
        if npm_file.exists() and npm_file.stat().st_size > 0:
            try:
                with open(npm_file) as f:
                    npm_data = json.load(f)
                    for pkg, vuln in npm_data.get('vulnerabilities', {}).items():
                        sev_map = {'critical':'critical','high':'high','moderate':'medium','low':'low','info':'info'}
                        sev = sev_map.get(vuln.get('severity','low'), 'low')
                        severity_summary[sev].append(dict(
                            tool='npm_audit', file='./package.json',
                            issue=pkg, message=vuln.get('title','Security vulnerability'),
                            severity=vuln.get('severity','low')))
            except Exception as e:
                print('Error processing npm_audit.json: ' + str(e))

        # Process Retire.js results
        retire_file = report_dir / 'retire.json'
        if retire_file.exists() and retire_file.stat().st_size > 0:
            try:
                with open(retire_file) as f:
                    retire_data = json.load(f)
                    for file_entry in retire_data.get('data', []):
                        for component in file_entry.get('results', []):
                            for vuln in component.get('vulnerabilities', []):
                                sev_map = {'critical':'critical','high':'high','medium':'medium','moderate':'medium','low':'low'}
                                sev = sev_map.get(vuln.get('severity','low'), 'low')
                                severity_summary[sev].append(dict(
                                    tool='retire',
                                    file=file_entry.get('file','unknown'),
                                    issue=component.get('component','unknown'),
                                    message=vuln.get('identifiers',{}).get('summary','vulnerability'),
                                    severity=vuln.get('severity','medium')))
            except Exception as e:
                print('Error processing retire.json: ' + str(e))

        # Process Plato results
        plato_file = report_dir / 'plato-report' / 'report.json'
        if plato_file.exists() and plato_file.stat().st_size > 0:
            try:
                with open(plato_file) as f:
                    plato_data = json.load(f)
                    for file_path, report_item in plato_data.get('reports', {}).items():
                        if isinstance(report_item, dict):
                            complexity = report_item.get('complexity',{}).get('aggregate',{}).get('cyclomatic',0)
                            if complexity > 15:
                                severity_summary['high'].append(dict(tool='plato', file=file_path, line=1, issue='high_complexity', message='Cyclomatic complexity: '+str(complexity)))
                            elif complexity > 10:
                                severity_summary['medium'].append(dict(tool='plato', file=file_path, line=1, issue='medium_complexity', message='Cyclomatic complexity: '+str(complexity)))
            except Exception as e:
                print('Error processing plato report: ' + str(e))

        # Process JSCPD results
        jscpd_file = report_dir / 'jscpd-report.json'
        if jscpd_file.exists() and jscpd_file.stat().st_size > 0:
            try:
                with open(jscpd_file) as f:
                    jscpd_data = json.load(f)
                    dupes = jscpd_data.get('duplicates', [])
                    if isinstance(dupes, list):
                        for dup in dupes:
                            severity_summary['medium'].append(dict(
                                tool='jscpd', file=dup.get('firstFile',{}).get('name','unknown'),
                                line=1, issue='code_duplication',
                                message='Duplicate: '+str(dup.get('lines',0))+' lines'))
                    total = jscpd_data.get('statistics',{}).get('total',{})
                    pct = total.get('percentage', 0)
                    if pct > 0:
                        severity_summary['info'].append(dict(tool='jscpd', file='./', line=1, issue='duplication_summary', message='Duplication: '+str(round(pct,1))+'%'))
            except Exception as e:
                print('Error processing jscpd-report.json: ' + str(e))

        # Process JSDoc results
        jsdoc_file = report_dir / 'jsdoc.json'
        if jsdoc_file.exists() and jsdoc_file.stat().st_size > 0:
            try:
                with open(jsdoc_file) as f:
                    jsdoc_data = json.load(f)
                    if isinstance(jsdoc_data, list):
                        for entry in jsdoc_data:
                            if isinstance(entry, dict) and entry.get('undocumented', False):
                                severity_summary['info'].append(dict(
                                    tool='jsdoc',
                                    file=entry.get('meta',{}).get('filename','unknown'),
                                    line=entry.get('meta',{}).get('lineno',1),
                                    issue='missing_jsdoc', message='Missing JSDoc for: '+entry.get('name','unknown')))
                        severity_summary['info'].append(dict(tool='jsdoc', file='./', line=1, issue='doc_scan', message='JSDoc scanned '+str(len(jsdoc_data))+' symbols'))
            except Exception as e:
                print('Error processing jsdoc.json: ' + str(e))

        # Process OSV Scanner results
        osv_file = report_dir / 'osv_scanner.json'
        if osv_file.exists() and osv_file.stat().st_size > 0:
            try:
                with open(osv_file) as f:
                    osv_data = json.load(f)
                    for result in osv_data.get('results', []):
                        for pkg in result.get('packages', []):
                            for vuln in pkg.get('vulnerabilities', []):
                                sev_map = {'CRITICAL':'critical','HIGH':'high','MODERATE':'medium','MEDIUM':'medium','LOW':'low'}
                                db_sev = ''
                                for s in vuln.get('database_specific', {}).get('severity', ''):
                                    if isinstance(s, str):
                                        db_sev = s
                                sev = sev_map.get(db_sev.upper(), 'medium')
                                severity_summary[sev].append(dict(
                                    tool='osv_scanner',
                                    file=pkg.get('package', {}).get('name', 'unknown'),
                                    line=1,
                                    issue=vuln.get('id', 'unknown'),
                                    message=vuln.get('summary', 'Vulnerability detected')
                                ))
            except Exception as e:
                print('Error processing osv_scanner.json: ' + str(e))

        # Process Syft SBOM results
        syft_file = report_dir / 'syft.json'
        if syft_file.exists() and syft_file.stat().st_size > 0:
            try:
                with open(syft_file) as f:
                    syft_data = json.load(f)
                    artifacts = syft_data.get('artifacts', [])
                    severity_summary['info'].append(dict(
                        tool='syft',
                        file='./',
                        line=1,
                        issue='sbom_summary',
                        message='SBOM: ' + str(len(artifacts)) + ' packages detected'
                    ))
                    for artifact in artifacts:
                        severity_summary['info'].append(dict(
                            tool='syft',
                            file=artifact.get('name', 'unknown'),
                            line=1,
                            issue='package_detected',
                            message=artifact.get('name', '') + '@' + artifact.get('version', 'unknown') + ' (' + artifact.get('type', 'unknown') + ')'
                        ))
            except Exception as e:
                print('Error processing syft.json: ' + str(e))

        # Process Trivy results
        trivy_file = report_dir / 'trivy.json'
        if trivy_file.exists() and trivy_file.stat().st_size > 0:
            try:
                with open(trivy_file) as f:
                    trivy_data = json.load(f)
                    for result in trivy_data.get('Results', []):
                        for vuln in result.get('Vulnerabilities', []):
                            sev_map = {'CRITICAL':'critical','HIGH':'high','MEDIUM':'medium','LOW':'low','UNKNOWN':'info'}
                            sev = sev_map.get(vuln.get('Severity', 'UNKNOWN').upper(), 'medium')
                            severity_summary[sev].append(dict(
                                tool='trivy',
                                file=result.get('Target', 'unknown'),
                                line=1,
                                issue=vuln.get('VulnerabilityID', 'unknown'),
                                message=vuln.get('Title', vuln.get('Description', 'Vulnerability detected'))
                            ))
            except Exception as e:
                print('Error processing trivy.json: ' + str(e))

        # Process Grype results
        grype_file = report_dir / 'grype.json'
        if grype_file.exists() and grype_file.stat().st_size > 0:
            try:
                with open(grype_file) as f:
                    grype_data = json.load(f)
                    for match in grype_data.get('matches', []):
                        vuln = match.get('vulnerability', {})
                        sev_map = {'Critical':'critical','High':'high','Medium':'medium','Low':'low','Negligible':'info'}
                        sev = sev_map.get(vuln.get('severity', 'Medium'), 'medium')
                        severity_summary[sev].append(dict(
                            tool='grype',
                            file=match.get('artifact', {}).get('name', 'unknown'),
                            line=1,
                            issue=vuln.get('id', 'unknown'),
                            message=vuln.get('description', 'Vulnerability detected')
                        ))
            except Exception as e:
                print('Error processing grype.json: ' + str(e))

        # Process ScanCode results
        scancode_file = report_dir / 'scancode.json'
        if scancode_file.exists() and scancode_file.stat().st_size > 0:
            try:
                with open(scancode_file) as f:
                    scancode_data = json.load(f)
                    for file_entry in scancode_data.get('files', []):
                        for license_det in file_entry.get('license_detections', []):
                            severity_summary['info'].append(dict(
                                tool='scancode',
                                file='./' + file_entry.get('path', 'unknown').lstrip('./'),
                                line=1,
                                issue='license_detection',
                                message='License: ' + license_det.get('license_expression', 'unknown')
                            ))
                        for copyright_det in file_entry.get('copyrights', []):
                            severity_summary['info'].append(dict(
                                tool='scancode',
                                file='./' + file_entry.get('path', 'unknown').lstrip('./'),
                                line=1,
                                issue='copyright_detection',
                                message='Copyright: ' + copyright_det.get('copyright', 'unknown')
                            ))
            except Exception as e:
                print('Error processing scancode.json: ' + str(e))

        # Process TruffleHog results (both filesystem and git scans)
        trufflehog_files = ['trufflehog.json', 'trufflehog_git.json']
        for trufflehog_filename in trufflehog_files:
            trufflehog_file = report_dir / trufflehog_filename
            if trufflehog_file.exists() and trufflehog_file.stat().st_size > 0:
                try:
                    with open(trufflehog_file) as f:
                        trufflehog_data = json.load(f)
                        if isinstance(trufflehog_data, dict) and 'FoundIssues' in trufflehog_data:
                            for finding in trufflehog_data.get('FoundIssues', []):
                                source_type = 'git' if 'git' in trufflehog_filename else 'filesystem'
                                severity_summary['critical'].append(dict(
                                    tool='trufflehog',
                                    file=finding.get('SourceMetadata', {}).get('Data', {}).get('Filesystem', {}).get('file', 'unknown'),
                                    line=finding.get('SourceMetadata', {}).get('Data', {}).get('Filesystem', {}).get('line', 1),
                                    issue=finding.get('DetectorName', 'secret_detected'),
                                    message='Secret detected (' + source_type + '): ' + finding.get('DetectorName', 'unknown type')
                                ))
                        elif isinstance(trufflehog_data, list):
                            source_type = 'git' if 'git' in trufflehog_filename else 'filesystem'
                            for finding in trufflehog_data:
                                severity_summary['critical'].append(dict(
                                    tool='trufflehog',
                                    file=finding.get('SourceMetadata', {}).get('Data', {}).get('Filesystem', {}).get('file', 'unknown'),
                                    line=finding.get('SourceMetadata', {}).get('Data', {}).get('Filesystem', {}).get('line', 1),
                                    issue=finding.get('DetectorName', 'secret_detected'),
                                    message='Secret detected (' + source_type + '): ' + finding.get('DetectorName', 'unknown type')
                                ))
                except Exception as e:
                    print('Error processing ' + trufflehog_filename + ': ' + str(e))

        # Process Gitleaks results
        gitleaks_file = report_dir / 'gitleaks.json'
        if gitleaks_file.exists() and gitleaks_file.stat().st_size > 0:
            try:
                with open(gitleaks_file) as f:
                    gitleaks_data = json.load(f)
                    if isinstance(gitleaks_data, list):
                        for finding in gitleaks_data:
                            severity_summary['critical'].append(dict(
                                tool='gitleaks',
                                file=finding.get('File', 'unknown'),
                                line=finding.get('StartLine', 1),
                                issue=finding.get('RuleID', 'secret_detected'),
                                message='Secret: ' + finding.get('Description', 'Secret detected')
                            ))
            except Exception as e:
                print('Error processing gitleaks.json: ' + str(e))

        output_file = report_dir / 'severity_summary.json'
        with open(output_file, 'w') as f:
            json.dump(severity_summary, f, indent=2)
        print('=== FINAL SEVERITY SUMMARY ===')
        for sev, issues in severity_summary.items():
            print(sev + ': ' + str(len(issues)) + ' issues')
        PYEOF

    - name: Verify scan outputs
      run: |
        echo "=== Report directory ==="
        ls -laR $REPORT_DIR
        echo "=== Checking artifacts ==="
        test -f $REPORT_DIR/eslint.json || echo "❌ eslint missing"
        test -f $REPORT_DIR/npm_audit.json || echo "❌ npm_audit missing"
        test -f $REPORT_DIR/retire.json || echo "❌ retire missing"
        test -f $REPORT_DIR/jscpd-report.json || echo "❌ jscpd missing"
        test -f $REPORT_DIR/jsdoc.json || echo "❌ jsdoc missing"
        test -f $REPORT_DIR/plato-report/report.json || echo "❌ plato missing"
        test -f $REPORT_DIR/osv_scanner.json || echo "❌ osv_scanner missing"
        test -f $REPORT_DIR/syft.json || echo "❌ syft missing"
        test -f $REPORT_DIR/trivy.json || echo "❌ trivy missing"
        test -f $REPORT_DIR/grype.json || echo "❌ grype missing"
        test -f $REPORT_DIR/scancode.json || echo "❌ scancode missing"
        test -f $REPORT_DIR/trufflehog.json || echo "❌ trufflehog filesystem missing"
        test -f $REPORT_DIR/trufflehog_git.json || echo "❌ trufflehog git missing"
        test -f $REPORT_DIR/gitleaks.json || echo "❌ gitleaks missing"
        echo "=== severity_summary.json ==="
        cat $REPORT_DIR/severity_summary.json || echo "severity_summary.json MISSING"

    - name: Upload scan reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: node-scan-reports
        path: ${{ env.REPORT_DIR }}/
        retention-days: 30
